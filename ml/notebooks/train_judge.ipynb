{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc476c24",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da18f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20087bc8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6033abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgeModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int = 64,\n",
    "        num_classes: int = 3\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.net(x)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"probs\": probs\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c307b520",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26eddafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgeDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X)\n",
    "        self.y = torch.tensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a61718",
   "metadata": {},
   "source": [
    "## Generation synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88202549",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERDICTS = {\"publish\": 0, \"revise\": 1, \"reject\": 2}\n",
    "\n",
    "def generate_judge_sample():\n",
    "    risk = random.random()\n",
    "    uncertainty = random.random() * 0.3\n",
    "    quality = random.random()\n",
    "\n",
    "    aspects = [random.uniform(0.3, 1.0) for _ in range(4)]\n",
    "\n",
    "    features = [\n",
    "        risk,\n",
    "        uncertainty,\n",
    "        quality,\n",
    "        1 - np.std(aspects),\n",
    "        *aspects\n",
    "    ]\n",
    "\n",
    "    if risk > 0.7:\n",
    "        label = VERDICTS[\"reject\"]\n",
    "    elif risk < 0.3 and quality > 0.7:\n",
    "        label = VERDICTS[\"publish\"]\n",
    "    else:\n",
    "        label = VERDICTS[\"revise\"]\n",
    "\n",
    "    return np.array(features, dtype=\"float32\"), label\n",
    "\n",
    "\n",
    "def generate_judge_dataset(n=5000):\n",
    "    X, y = [], []\n",
    "    for _ in range(n):\n",
    "        f, l = generate_judge_sample()\n",
    "        X.append(f)\n",
    "        y.append(l)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a28e561",
   "metadata": {},
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c8b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_judge(dataset, input_dim: int):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = JudgeModel(input_dim=input_dim).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    epochs = 10\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        loop = tqdm.tqdm(loader, desc=f\"Epoch {epoch + 1}\")\n",
    "\n",
    "        for x, y in loop:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            out = model(x)\n",
    "            loss = criterion(out[\"logits\"], y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: loss={epoch_loss / len(loader):.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c75cd3",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f5b73e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z9/19wy68_x711cm327qjf79_pc0000gn/T/ipykernel_1243/3878342614.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)\n",
      "  self.X = torch.tensor(X)\n",
      "Epoch 1: 100%|██████████| 157/157 [00:00<00:00, 406.24it/s, loss=0.382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.6849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 157/157 [00:00<00:00, 931.93it/s, loss=0.167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=0.2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 157/157 [00:00<00:00, 958.50it/s, loss=0.0966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss=0.2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 157/157 [00:00<00:00, 927.12it/s, loss=0.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: loss=0.1845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 157/157 [00:00<00:00, 873.27it/s, loss=0.0926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: loss=0.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 157/157 [00:00<00:00, 554.16it/s, loss=0.271] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: loss=0.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 157/157 [00:00<00:00, 732.67it/s, loss=0.189] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: loss=0.1452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 157/157 [00:00<00:00, 937.12it/s, loss=0.0372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: loss=0.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 157/157 [00:00<00:00, 910.22it/s, loss=0.131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: loss=0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 157/157 [00:00<00:00, 561.94it/s, loss=0.292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: loss=0.1325\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_judge_dataset()\n",
    "dataset = JudgeDataset(X, y)\n",
    "\n",
    "model = train_judge(dataset, input_dim=X[0].shape[0])\n",
    "torch.save(model.state_dict(), \"judge.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
