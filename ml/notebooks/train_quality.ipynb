{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "95b34a00",
      "metadata": {
        "id": "95b34a00"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4db78535",
      "metadata": {
        "id": "4db78535"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexvasyukov/Documents/GitHub/multi-agent-reviewer/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156fe900",
      "metadata": {
        "id": "156fe900"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4b52b182",
      "metadata": {
        "id": "4b52b182"
      },
      "outputs": [],
      "source": [
        "class QualityModel(nn.Module):\n",
        "    def __init__(self, encoder_name: str, hidden_dim: int = 256):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
        "        emb_dim = self.encoder.config.hidden_size\n",
        "\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(emb_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "        )\n",
        "\n",
        "        self.heads = nn.ModuleDict({\n",
        "            \"informativeness\": nn.Linear(hidden_dim, 1),\n",
        "            \"clarity\": nn.Linear(hidden_dim, 1),\n",
        "            \"completeness\": nn.Linear(hidden_dim, 1),\n",
        "            \"persuasion\": nn.Linear(hidden_dim, 1),\n",
        "        })\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, **kwargs):\n",
        "        out = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        pooled = out.last_hidden_state[:, 0]\n",
        "        shared = self.shared(pooled)\n",
        "\n",
        "        aspects = {\n",
        "            name: head(shared).squeeze(-1)\n",
        "            for name, head in self.heads.items()\n",
        "        }\n",
        "\n",
        "        quality_score = torch.stack(list(aspects.values()), dim=1).mean(dim=1)\n",
        "\n",
        "        return {\n",
        "            \"quality_score\": quality_score,\n",
        "            \"aspects\": aspects\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34cd51cf",
      "metadata": {
        "id": "34cd51cf"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fbabcc20",
      "metadata": {
        "id": "fbabcc20"
      },
      "outputs": [],
      "source": [
        "class QualityDataset(Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.samples[idx]\n",
        "        return {\n",
        "            \"text\": s[\"text\"],\n",
        "            \"informativeness\": torch.tensor(s[\"informativeness\"]),\n",
        "            \"clarity\": torch.tensor(s[\"clarity\"]),\n",
        "            \"completeness\": torch.tensor(s[\"completeness\"]),\n",
        "            \"persuasion\": torch.tensor(s[\"persuasion\"]),\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da47745c",
      "metadata": {
        "id": "da47745c"
      },
      "source": [
        "## Generation synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "85640bb2",
      "metadata": {
        "id": "85640bb2"
      },
      "outputs": [],
      "source": [
        "def make_quality_sample(kind: str):\n",
        "    if kind == \"good\":\n",
        "        text = \"–ü—Ä–æ–¥–∞—é –≤–µ–ª–æ—Å–∏–ø–µ–¥. –û—Ç–ª–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è 6 –º–µ—Å—è—Ü–µ–≤. –ü—Ä–∏—á–∏–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏ ‚Äî –ø–æ–∫—É–ø–∫–∞ –Ω–æ–≤–æ–≥–æ.\"\n",
        "        scores = {\n",
        "            \"informativeness\": random.uniform(0.7, 0.9),\n",
        "            \"clarity\": random.uniform(0.7, 0.9),\n",
        "            \"completeness\": random.uniform(0.7, 0.9),\n",
        "            \"persuasion\": random.uniform(0.5, 0.8),\n",
        "        }\n",
        "\n",
        "    elif kind == \"short\":\n",
        "        text = \"–ü—Ä–æ–¥–∞–º –≤–µ–ª–æ—Å–∏–ø–µ–¥\"\n",
        "        scores = {\n",
        "            \"informativeness\": random.uniform(0.2, 0.4),\n",
        "            \"clarity\": random.uniform(0.6, 0.7),\n",
        "            \"completeness\": random.uniform(0.2, 0.4),\n",
        "            \"persuasion\": random.uniform(0.3, 0.4),\n",
        "        }\n",
        "\n",
        "    elif kind == \"spam\":\n",
        "        text = \"üî•üî•üî• –ö–£–ü–ò –°–ï–ô–ß–ê–° !!! üî•üî•üî•\"\n",
        "        scores = {\n",
        "            \"informativeness\": random.uniform(0.2, 0.4),\n",
        "            \"clarity\": random.uniform(0.2, 0.4),\n",
        "            \"completeness\": random.uniform(0.2, 0.4),\n",
        "            \"persuasion\": random.uniform(0.7, 0.9),\n",
        "        }\n",
        "\n",
        "    else:  # bad\n",
        "        text = \"!!!\"\n",
        "        scores = {k: 0.1 for k in [\"informativeness\", \"clarity\", \"completeness\", \"persuasion\"]}\n",
        "\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        **scores\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_quality_dataset(n=2000):\n",
        "    kinds = [\"good\", \"short\", \"spam\", \"bad\"]\n",
        "    return [make_quality_sample(random.choice(kinds)) for _ in range(n)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6f040a",
      "metadata": {
        "id": "7e6f040a"
      },
      "source": [
        "## Train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee1651ee",
      "metadata": {
        "id": "ee1651ee"
      },
      "outputs": [],
      "source": [
        "def train_quality_model(dataset, encoder_name: str):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(encoder_name)\n",
        "    model = QualityModel(encoder_name).to(device)\n",
        "\n",
        "    for p in model.encoder.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    epochs = 5\n",
        "\n",
        "    def collate(batch):\n",
        "        texts = [b[\"text\"] for b in batch]\n",
        "        labels = {k: torch.tensor([b[k] for b in batch]) for k in [\"informativeness\",\"clarity\",\"completeness\",\"persuasion\"]}\n",
        "        return texts, labels\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        loop = tqdm.tqdm(loader, desc=f\"Epoch {epoch + 1}\")\n",
        "\n",
        "        for texts, labels in loop:\n",
        "            tokens = tokenizer(\n",
        "                texts,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "            tokens = {k: v.to(device) for k, v in tokens.items()}\n",
        "            labels = {k: v.to(device) for k, v in labels.items()}\n",
        "\n",
        "            out = model(**tokens)\n",
        "\n",
        "            loss = 0.0\n",
        "            for aspect, pred in out[\"aspects\"].items():\n",
        "                loss += criterion(torch.sigmoid(pred), labels[aspect])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: loss={epoch_loss / len(loader):.4f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1564c7",
      "metadata": {
        "id": "0f1564c7"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b5ee26c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5ee26c7",
        "outputId": "a3d679bc-8c2c-4fc7-d2c3-4639b0946499"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [00:19<00:00,  9.78it/s, loss=0.0499]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=0.1057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 / 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [00:17<00:00, 10.88it/s, loss=0.0202]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: loss=0.0381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 / 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [00:16<00:00, 11.71it/s, loss=0.0136] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: loss=0.0153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 / 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [00:16<00:00, 11.67it/s, loss=0.00628]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: loss=0.0093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5 / 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [00:16<00:00, 11.69it/s, loss=0.00796]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: loss=0.0077\n"
          ]
        }
      ],
      "source": [
        "samples = generate_quality_dataset(3000)\n",
        "dataset = QualityDataset(samples)\n",
        "\n",
        "model = train_quality_model(\n",
        "    dataset,\n",
        "    encoder_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        ")\n",
        "\n",
        "torch.save(model.state_dict(), \"quality.pt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
